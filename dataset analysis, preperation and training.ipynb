{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec68397a",
   "metadata": {},
   "source": [
    "Opis:..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c4b68",
   "metadata": {},
   "source": [
    "Generisanje datafrejma - funkcije za pripremu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41067b23-f757-482c-a75f-fc3108c9b4c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd4c4af-8a78-42a3-a23d-b8e9f6e22c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(annotations_folder_path):\n",
    "    annotations = []\n",
    "    for annotation_name in tqdm(os.listdir(annotations_folder_path)):\n",
    "        annotation_path = os.path.join(annotations_folder_path, annotation_name)\n",
    "        annotation = json.load(open(annotation_path))\n",
    "        annotation[\"filename\"] = annotation_name.replace(\".json\", \"\")\n",
    "        annotations.append(annotation)\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5766df5-b573-48b4-8592-c6b14629d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_dict(input_dict, base_key=\"\", output_dict={}, index_value=None):\n",
    "    \n",
    "    for key in input_dict.keys():\n",
    "        \n",
    "        if base_key == \"\":\n",
    "            full_key = key     \n",
    "        else:\n",
    "            if index_value is None:\n",
    "                full_key = base_key + \"/\" + key\n",
    "            else:\n",
    "                full_key = base_key + \"/\" + key + \"/\" + index_value\n",
    "\n",
    "        if isinstance(input_dict[key], dict):\n",
    "            get_flattened_dict(input_dict[key], full_key, output_dict)\n",
    "            \n",
    "        elif isinstance(input_dict[key], list):\n",
    "            for index, item in enumerate(input_dict[key]):\n",
    "                full_list_key = full_key\n",
    "                get_flattened_dict(item, full_list_key, output_dict, str(index))\n",
    "                    \n",
    "        else:\n",
    "            output_dict[full_key] = input_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5005aea6-8e89-4ef1-ad86-abaaa439fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_ORDER_DICT = {\n",
    "    \"description\": \"00-00000-00\",\n",
    "    \"tags\":[],\n",
    "    \"size\": {\n",
    "        \"width\": \"02-0000-00\",\n",
    "        \"height\": \"03-0000-00\"\n",
    "    },\n",
    "    \"objects\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46cd044-ab9c-4dd4-8e2a-18aeb7edc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_index(split_key, key_order_dict, level=0, id_value=None):\n",
    "    key = split_key[level]\n",
    "   \n",
    "        \n",
    "    if isinstance(key_order_dict[key], dict):\n",
    "        return get_column_index(split_key, key_order_dict[key], level+1, id_value)\n",
    "    \n",
    "    else:\n",
    "        column_index = key_order_dict[key]\n",
    "        if id_value is not None:\n",
    "            split_column_index = column_index.split(\"-\")\n",
    "            split_column_index[1] = split_column_index[1].replace(\"id\", id_value)[-5:]\n",
    "            column_index = \"-\".join(split_column_index)\n",
    "        return column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc4bc4e-4b34-42ff-9a44-872a98ed0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_sorted_columns(annotation_df_columns):\n",
    "    sorted_annotation_df_cols = []\n",
    "    for annotation_df_col in annotation_df_columns:\n",
    "        split_col = annotation_df_col.split(\"/\")\n",
    "        col_index = get_column_index(split_col, KEY_ORDER_DICT, 0)\n",
    "        sorted_annotation_df_cols.append(str(col_index) + \"#\" + annotation_df_col)\n",
    "    sorted_annotation_df_cols.sort()\n",
    "    sorted_annotation_df_cols = [sorted_annotation_df_col.split(\"#\")[1] for sorted_annotation_df_col in sorted_annotation_df_cols]\n",
    "    return sorted_annotation_df_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ad05be-5afa-410b-806b-4488c944975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_df(annotations):\n",
    "    annotation_dicts = []\n",
    "    for annotation in annotations:\n",
    "        annotation_dict = {}\n",
    "        get_flattened_dict(annotation, \"\", annotation_dict)\n",
    "        annotation_dicts.append(annotation_dict)\n",
    "    annotation_dicts_keys = set(list(itertools.chain.from_iterable([list(annotation_dict.keys()) for annotation_dict in annotation_dicts])))\n",
    "    annotation_dicts_keys = get_sorted_columns(list(annotation_dicts_keys))\n",
    "    annotation_df_dict = {key: [] for key in annotation_dicts_keys}\n",
    "    for annotation_dict in annotation_dicts:\n",
    "        for key in annotation_df_dict:\n",
    "            value = annotation_dict[key] if key in annotation_dict else np.nan\n",
    "            annotation_df_dict[key].append(value)\n",
    "    json_df = pd.DataFrame(annotation_df_dict)\n",
    "    return json_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa3571a",
   "metadata": {},
   "source": [
    "Generisanje datafrejma - sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8f2c68f-232c-4aa0-b129-19319ed3e43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:00<00:00, 432.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>size</th>\n",
       "      <th>objects</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10789675, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 88945149, 'classId': 6508807, 'descrip...</td>\n",
       "      <td>b1f6c103-8b75ea3e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10790092, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 88948965, 'classId': 6508804, 'descrip...</td>\n",
       "      <td>b25fb716-78d8d49b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10790221, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 88950127, 'classId': 6508807, 'descrip...</td>\n",
       "      <td>b26f9b1e-3e172ced.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10790369, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 88952159, 'classId': 6508807, 'descrip...</td>\n",
       "      <td>b289f2e8-cec8700d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10791039, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 88959006, 'classId': 6508807, 'descrip...</td>\n",
       "      <td>b313a4dc-217f1233.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10818874, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 89256297, 'classId': 6508804, 'descrip...</td>\n",
       "      <td>c9b9fef4-a58bf3d5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10818931, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 89256888, 'classId': 6508800, 'descrip...</td>\n",
       "      <td>c9c31e57-45b42452.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10819441, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 89261734, 'classId': 6508807, 'descrip...</td>\n",
       "      <td>ca28f275-03f8cef5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10819429, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 89261594, 'classId': 6508807, 'descrip...</td>\n",
       "      <td>ca28f275-cac4f254.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td></td>\n",
       "      <td>[{'id': 10819405, 'tagId': 26739, 'name': 'wea...</td>\n",
       "      <td>{'height': 720, 'width': 1280}</td>\n",
       "      <td>[{'id': 89261361, 'classId': 6508800, 'descrip...</td>\n",
       "      <td>ca2ba838-fdddb1fb.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    description                                               tags  \\\n",
       "0                [{'id': 10789675, 'tagId': 26739, 'name': 'wea...   \n",
       "1                [{'id': 10790092, 'tagId': 26739, 'name': 'wea...   \n",
       "2                [{'id': 10790221, 'tagId': 26739, 'name': 'wea...   \n",
       "3                [{'id': 10790369, 'tagId': 26739, 'name': 'wea...   \n",
       "4                [{'id': 10791039, 'tagId': 26739, 'name': 'wea...   \n",
       "..          ...                                                ...   \n",
       "104              [{'id': 10818874, 'tagId': 26739, 'name': 'wea...   \n",
       "105              [{'id': 10818931, 'tagId': 26739, 'name': 'wea...   \n",
       "106              [{'id': 10819441, 'tagId': 26739, 'name': 'wea...   \n",
       "107              [{'id': 10819429, 'tagId': 26739, 'name': 'wea...   \n",
       "108              [{'id': 10819405, 'tagId': 26739, 'name': 'wea...   \n",
       "\n",
       "                               size  \\\n",
       "0    {'height': 720, 'width': 1280}   \n",
       "1    {'height': 720, 'width': 1280}   \n",
       "2    {'height': 720, 'width': 1280}   \n",
       "3    {'height': 720, 'width': 1280}   \n",
       "4    {'height': 720, 'width': 1280}   \n",
       "..                              ...   \n",
       "104  {'height': 720, 'width': 1280}   \n",
       "105  {'height': 720, 'width': 1280}   \n",
       "106  {'height': 720, 'width': 1280}   \n",
       "107  {'height': 720, 'width': 1280}   \n",
       "108  {'height': 720, 'width': 1280}   \n",
       "\n",
       "                                               objects               filename  \n",
       "0    [{'id': 88945149, 'classId': 6508807, 'descrip...  b1f6c103-8b75ea3e.jpg  \n",
       "1    [{'id': 88948965, 'classId': 6508804, 'descrip...  b25fb716-78d8d49b.jpg  \n",
       "2    [{'id': 88950127, 'classId': 6508807, 'descrip...  b26f9b1e-3e172ced.jpg  \n",
       "3    [{'id': 88952159, 'classId': 6508807, 'descrip...  b289f2e8-cec8700d.jpg  \n",
       "4    [{'id': 88959006, 'classId': 6508807, 'descrip...  b313a4dc-217f1233.jpg  \n",
       "..                                                 ...                    ...  \n",
       "104  [{'id': 89256297, 'classId': 6508804, 'descrip...  c9b9fef4-a58bf3d5.jpg  \n",
       "105  [{'id': 89256888, 'classId': 6508800, 'descrip...  c9c31e57-45b42452.jpg  \n",
       "106  [{'id': 89261734, 'classId': 6508807, 'descrip...  ca28f275-03f8cef5.jpg  \n",
       "107  [{'id': 89261594, 'classId': 6508807, 'descrip...  ca28f275-cac4f254.jpg  \n",
       "108  [{'id': 89261361, 'classId': 6508800, 'descrip...  ca2ba838-fdddb1fb.jpg  \n",
       "\n",
       "[109 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annotations_path = \"bdd100ksample/val/ann\"\n",
    "train_annotations = load_annotations(train_annotations_path)\n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame.from_dict(train_annotations, orient='columns')\n",
    "\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c859f",
   "metadata": {},
   "source": [
    "Pregled objekata sample dataseta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422f639",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f7cd6f3-936b-44b5-9a5f-78784470087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "objetcs_id_dict = {\n",
    "    0: 'car',\n",
    "    1: 'bus',\n",
    "    2: 'drivable area',\n",
    "    3: 'lane',\n",
    "    4: 'traffic sign',\n",
    "    5: 'truck',\n",
    "    6: 'person',\n",
    "    7: 'traffic light',\n",
    "    8: 'rider',\n",
    "    9: 'bike',\n",
    "    10:'motor',\n",
    "    11:'train'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9b704c0-49ee-4001-8b67-b40e036d1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totals = pd.DataFrame({\n",
    "    'car':[0],\n",
    "    'bus':[0],\n",
    "    'drivable area':[0],\n",
    "    'lane':[0],\n",
    "    'traffic sign':[0],\n",
    "    'truck':[0],\n",
    "    'person':[0],\n",
    "    'traffic light':[0],\n",
    "    'rider':[0],\n",
    "    'bike':[0],\n",
    "    'motor':[0],\n",
    "    'train':[0]\n",
    "})\n",
    "df_per_picture = pd.DataFrame({\n",
    "    'car':[0],\n",
    "    'bus':[0],\n",
    "    'drivable area':[0],\n",
    "    'lane':[0],\n",
    "    'traffic sign':[0],\n",
    "    'truck':[0],\n",
    "    'person':[0],\n",
    "    'traffic light':[0],\n",
    "    'rider':[0],\n",
    "    'bike':[0],\n",
    "    'motor':[0],\n",
    "    'train':[0]\n",
    "})\n",
    "\n",
    "for i in range(len(df2.index)): \n",
    "    picture_flags = [False, False, False, False, False, False, False, False, False, False, False, False]\n",
    "    for o in df2.loc[i,'objects']:\n",
    "        o_id = (o['classId']-6508800)\n",
    "        df_totals.loc[0,objetcs_id_dict[o_id]] = df_totals.loc[0,objetcs_id_dict[o_id]] + 1\n",
    "        if not picture_flags[o_id]:\n",
    "            df_per_picture.loc[0,objetcs_id_dict[o_id]] = df_per_picture.loc[0,objetcs_id_dict[o_id]] + 1\n",
    "            picture_flags[o_id] = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dcd21e5-87ab-412e-8354-3f4d39edcb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "      <th>bus</th>\n",
       "      <th>drivable area</th>\n",
       "      <th>lane</th>\n",
       "      <th>traffic sign</th>\n",
       "      <th>truck</th>\n",
       "      <th>person</th>\n",
       "      <th>traffic light</th>\n",
       "      <th>rider</th>\n",
       "      <th>bike</th>\n",
       "      <th>motor</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1257</td>\n",
       "      <td>12</td>\n",
       "      <td>202</td>\n",
       "      <td>885</td>\n",
       "      <td>426</td>\n",
       "      <td>55</td>\n",
       "      <td>169</td>\n",
       "      <td>336</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    car  bus  drivable area  lane  traffic sign  truck  person  traffic light  \\\n",
       "0  1257   12            202   885           426     55     169            336   \n",
       "\n",
       "   rider  bike  motor  train  \n",
       "0      8    13     15      0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d5d629a-2107-485f-8956-fd20a9b39b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "      <th>bus</th>\n",
       "      <th>drivable area</th>\n",
       "      <th>lane</th>\n",
       "      <th>traffic sign</th>\n",
       "      <th>truck</th>\n",
       "      <th>person</th>\n",
       "      <th>traffic light</th>\n",
       "      <th>rider</th>\n",
       "      <th>bike</th>\n",
       "      <th>motor</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>11</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>97</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car  bus  drivable area  lane  traffic sign  truck  person  traffic light  \\\n",
       "0  109   11            107   105            97     37      44             74   \n",
       "\n",
       "   rider  bike  motor  train  \n",
       "0      7    10      4      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per_picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfef7b1",
   "metadata": {},
   "source": [
    "Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b93db",
   "metadata": {},
   "source": [
    "Transformacija anotacija u yolo format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad8b9c",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c3cdfd-0d2c-43c3-b31e-5d580aa1481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df2.index)):\n",
    "    save_location = \"bdd100ksample/train/labels/\" + df2.loc[i,'filename'].rstrip('.jpg') + \".txt\"\n",
    "    file = open(save_location,'w')\n",
    "    for o in df2.loc[i,'objects']:\n",
    "        if o['classId'] - 6508800 != 7:\n",
    "            continue\n",
    "        str_line = \"\"\n",
    "        str_line += (\"0 \")\n",
    "        str_line += (str((o['points']['exterior'][1][0]+o['points']['exterior'][0][0])/(2*1280)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][1]+o['points']['exterior'][0][1])/(2*720)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][0]-o['points']['exterior'][0][0])/(1280)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][1]-o['points']['exterior'][0][1])/(720)) + \"\\n\")\n",
    "        file.write(str_line)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd78521",
   "metadata": {},
   "source": [
    "Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66730bbe",
   "metadata": {},
   "source": [
    "Treniranje modela nad sample skupom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8bd546-f57f-4f4c-935e-e5c71c6f671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5a90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8487964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.24 ðŸš€ Python-3.12.2 torch-2.2.1+cpu CPU (AMD Ryzen 7 3700U with Radeon Vega Mobile Gfx)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=bdd100ksample/data.yaml, epochs=100, time=None, patience=100, batch=2, imgsz=1280, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train22, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train22\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train22', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\these\\Desktop\\tem\\bdd100ksample\\train\\labels.cache... 927 images, 27 backgrounds, 0 corrupt: 1\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\these\\Desktop\\tem\\bdd100ksample\\val\\labels.cache... 109 images, 35 backgrounds, 0 corrupt: 100%|\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train22\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train22\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100         0G      3.314      37.68      2.457         32       1280:   0%|          | 2/464 [00:26<1:41:06, 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbdd100ksample/data.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1280\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\gpu_env\\Lib\\site-packages\\ultralytics\\engine\\model.py:654\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 654\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\gpu_env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:208\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\gpu_env\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:384\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    380\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    381\u001b[0m     )\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\gpu_env\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = model.train(data='bdd100ksample/data.yaml', batch = 2, imgsz=1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f4f50",
   "metadata": {},
   "source": [
    "Prikaz rezultata nad test skupom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5355e45f-3726-4116-8d7f-fe6c61461483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307af4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "model = YOLO('mod2.pt')\n",
    "for img in tqdm(os.listdir( 'bdd100ksample/test/images')):\n",
    "    img_path = os.path.join('bdd100ksample/test/images', img)\n",
    "    imgs.append(img_path)\n",
    "    \n",
    "for img in imgs:\n",
    "    imgr = cv2.imread(img,1)\n",
    "    results = model(img)[0]\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "        cv2.rectangle(imgr, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "        cv2.putText(imgr, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "        cv2.imshow('',imgr)\n",
    "        if cv2.waitKey(0) == ord('q'):\n",
    "            break\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break      \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28831e10",
   "metadata": {},
   "source": [
    "Generisanje datafrejma - ceo dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc36e8",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde27da9-8e30-493a-8978-23227ad10b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69736/69736 [02:17<00:00, 506.18it/s]\n"
     ]
    }
   ],
   "source": [
    "train_annotations_path = \"bdd100k/train/ann\"\n",
    "train_annotations = load_annotations(train_annotations_path)\n",
    "\n",
    "df = pd.DataFrame.from_dict(train_annotations, orient='columns')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totals2 = pd.DataFrame({\n",
    "    'car':[0],\n",
    "    'bus':[0],\n",
    "    'drivable area':[0],\n",
    "    'lane':[0],\n",
    "    'traffic sign':[0],\n",
    "    'truck':[0],\n",
    "    'person':[0],\n",
    "    'traffic light':[0],\n",
    "    'rider':[0],\n",
    "    'bike':[0],\n",
    "    'motor':[0],\n",
    "    'train':[0]\n",
    "})\n",
    "df_per_picture2 = pd.DataFrame({\n",
    "    'car':[0],\n",
    "    'bus':[0],\n",
    "    'drivable area':[0],\n",
    "    'lane':[0],\n",
    "    'traffic sign':[0],\n",
    "    'truck':[0],\n",
    "    'person':[0],\n",
    "    'traffic light':[0],\n",
    "    'rider':[0],\n",
    "    'bike':[0],\n",
    "    'motor':[0],\n",
    "    'train':[0]\n",
    "})\n",
    "\n",
    "for i in range(len(df.index)): \n",
    "    picture_flags = [False, False, False, False, False, False, False, False, False, False, False, False]\n",
    "    for o in df.loc[i,'objects']:\n",
    "        o_id = (o['classId']-6508800)\n",
    "        df_totals2.loc[0,objetcs_id_dict[o_id]] = df_totals2.loc[0,objetcs_id_dict[o_id]] + 1\n",
    "        if not picture_flags[o_id]:\n",
    "            df_per_picture2.loc[0,objetcs_id_dict[o_id]] = df_per_picture2.loc[0,objetcs_id_dict[o_id]] + 1\n",
    "            picture_flags[o_id] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c379e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_picture2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b1812",
   "metadata": {},
   "source": [
    "Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406e228",
   "metadata": {},
   "source": [
    "Transformacija sample dataseta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca2b76",
   "metadata": {},
   "source": [
    "1. Brisanje svih slika i anotacija koje ne sadrze semafor u sebi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a54ca160-1063-4787-9a20-8c51d0bf7d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69736/69736 [00:00<00:00, 757942.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "jpg_dict = {}\n",
    "\n",
    "for picture in tqdm(os.listdir('bdd100ksample/train/images')):\n",
    "       jpg_dict[picture] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a113d2-ed0e-4777-8cb2-ea9661edbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df2.index:\n",
    "    for obj in df2['objects'][ind]:\n",
    "        if (obj['classId']-6508800)==7:\n",
    "            jpg_dict[df2['filename'][ind]] = True\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24824091-948c-480d-b376-e36ab33f186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in jpg_dict:\n",
    "    if not jpg_dict[pair]:\n",
    "        os.remove('bdd100k/train/ann/'+pair+'.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdc1de",
   "metadata": {},
   "source": [
    "2. Kopiranje slika iz celog dataseta u sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d2663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69736\n"
     ]
    }
   ],
   "source": [
    "jpg_dict = {}\n",
    "\n",
    "for ind in df.index:\n",
    "    jpg_dict[df['filename'][ind]] = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61cfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for picture in tqdm(os.listdir('bdd100ksample/train/images')):\n",
    "       jpg_dict[picture] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "768ce3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "sem_picture_num = 900-435\n",
    "no_sem_picture_num = 27\n",
    "for ind in df.index:\n",
    "    pic_filename = df['filename'][ind]\n",
    "    \n",
    "    if jpg_dict[pic_filename]:\n",
    "        continue\n",
    "        \n",
    "    is_sem_pic = False\n",
    "    for obj in df['objects'][ind]:\n",
    "        if (obj['classId']-6508800)==7:\n",
    "            shutil.copyfile('bdd100k/train/ann/'+pic_filename+'.json', 'bdd100ksample/train/ann/'+pic_filename+'.json')\n",
    "            shutil.copyfile('bdd100k/train/images/'+pic_filename, 'bdd100ksample/train/images/'+pic_filename)\n",
    "            sem_picture_num-=1\n",
    "            is_sem_pic = True\n",
    "            break\n",
    "    if not is_sem_pic and no_sem_picture_num > 0:\n",
    "        shutil.copyfile('bdd100k/train/ann/'+pic_filename+'.json', 'bdd100ksample/train/ann/'+pic_filename+'.json')\n",
    "        shutil.copyfile('bdd100k/train/images/'+pic_filename, 'bdd100ksample/train/images/'+pic_filename)\n",
    "        no_sem_picture_num-=1\n",
    "    if no_sem_picture_num==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c6f8b7",
   "metadata": {},
   "source": [
    "Prikaz rezultata sa poboljsanim sample datasetom ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd85fb",
   "metadata": {},
   "source": [
    "Transformacija celog dataseta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9c7c8",
   "metadata": {},
   "source": [
    "1. Smanjivanje broja slika bez semafora na 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_no_sem = 1000\n",
    "for ind in df.index:\n",
    "    to_delete = True\n",
    "    for obj in df['objects'][ind]:\n",
    "        if (obj['classId']-6508800)==7:\n",
    "            to_delete = False\n",
    "            break\n",
    "    if total_no_sem>0:\n",
    "        total_no_sem -=1\n",
    "        to_delete = False\n",
    "    if to_delete:\n",
    "        os.remove('bdd100k/train/ann/'+pair+'.json')\n",
    "        os.remove('bdd100k/train/images/'+pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb7045",
   "metadata": {},
   "source": [
    "ponovno ucitavanje dataseta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations_path = \"bdd100k/train/ann\"\n",
    "train_annotations = load_annotations(train_annotations_path)\n",
    "\n",
    "df = pd.DataFrame.from_dict(train_annotations, orient='columns')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b5c98a",
   "metadata": {},
   "source": [
    "2. Transformacija u yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a866d180-701f-46e3-ae42-e7f171145b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#srediti jos\n",
    "\n",
    "for i in range(len(df.index)):\n",
    "    save_location = \"bdd100k/train/labels/\" + df.loc[i,'filename'].rstrip('.jpg') + \".txt\"\n",
    "    file = open(save_location,'w')\n",
    "    for o in df.loc[i,'objects']:\n",
    "        if o['classId'] - 6508800 != 7:\n",
    "            continue\n",
    "        str_line = \"\"\n",
    "        str_line += (\"0 \")\n",
    "        str_line += (str((o['points']['exterior'][1][0]+o['points']['exterior'][0][0])/(2*1280)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][1]+o['points']['exterior'][0][1])/(2*720)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][0]-o['points']['exterior'][0][0])/(1280)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][1]-o['points']['exterior'][0][1])/(720)) + \"\\n\")\n",
    "        file.write(str_line)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71bd8a",
   "metadata": {},
   "source": [
    "Prikaz rezultata nad celim skupom..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9b6d538-be9c-4f4b-a650-296c8b16f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.index)): \n",
    "    img = cv2.imread(\"bdd100k/train/images/\"+df.loc[i,'filename'],1)\n",
    "   # print(i)\n",
    "    for o in df.loc[i,'objects']:\n",
    "        o_id = (o['classId']-6508800)\n",
    "        if o_id != 7:\n",
    "            continue\n",
    "        cv2.rectangle(img,(o['points']['exterior'][0][0],o['points']['exterior'][0][1]),(o['points']['exterior'][1][0],o['points']['exterior'][1][1]),(0,0,255),2)\n",
    "        cv2.imshow(df.loc[i,'filename'],img)\n",
    "        if cv2.waitKey(0) == ord('q'):\n",
    "            break\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break      \n",
    "    cv2.destroyAllWindows()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060b6683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 736x1280 (no detections), 7847.1ms\n",
      "Speed: 20.3ms preprocess, 7847.1ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 (no detections), 7451.6ms\n",
      "Speed: 14.4ms preprocess, 7451.6ms inference, 0.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 (no detections), 7928.8ms\n",
      "Speed: 20.2ms preprocess, 7928.8ms inference, 2.1ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n",
      "0: 736x1280 (no detections), 7907.9ms\n",
      "Speed: 10.2ms preprocess, 7907.9ms inference, 7.6ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m ret:\n\u001b[1;32m---> 26\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtolist():\n\u001b[0;32m     29\u001b[0m         x1, y1, x2, y2, score, class_id \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\engine\\model.py:169\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    148\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    149\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m    An alias for the predict method, enabling the model instance to be callable.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m        (List[ultralytics.engine.results.Results]): A list of prediction results, encapsulated in the Results class.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\engine\\model.py:429\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\engine\\predictor.py:204\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\engine\\predictor.py:283\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 283\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\engine\\predictor.py:140\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    136\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    139\u001b[0m )\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:384\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    381\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:  \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:  \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im)\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\nn\\tasks.py:83\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\nn\\tasks.py:101\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\nn\\tasks.py:122\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 122\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    123\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:225\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 225\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:225\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 225\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:335\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;124;03m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "VIDEOS_DIR = os.path.join('.', 'videos')\n",
    "\n",
    "video_path = 'vid5.mp4'\n",
    "video_path_out = '{}_out.mp4'.format(video_path)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "H, W, _ = frame.shape\n",
    "out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))\n",
    "\n",
    "\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('mod.pt')  # load a custom model\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "while ret:\n",
    "\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "\n",
    "        if score > threshold:\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "            cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    out.write(frame)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda346ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
