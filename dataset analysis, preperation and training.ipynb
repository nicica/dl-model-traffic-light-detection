{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec68397a",
   "metadata": {},
   "source": [
    "##### Disclaimer: this notebook is not complete yet\n",
    "\n",
    "The goal of this project is to create a model for real-time traffic light detection. The dataset used for this project is BDD100k,  however, the annotations and the whole dataset strcture was taken from https://datasetninja.com/bdd100k.\n",
    "\n",
    "This notebook covers analysis and preperation of the dataset for the training process and shows the results of it.\n",
    "\n",
    "For the training we are using the state-of-the-art Ultralytics YOLOv8 CV model and the sample version of the dataset with some changes to it.\n",
    "\n",
    "The whole process will be done in the follwing steps:\n",
    "1. Load the json files and generate a dataframe from it\n",
    "2. Review the dataframe\n",
    "3. Count the objects and store results to another dataframe\n",
    "4. Generate labels for the YOLO format and exclude all the objects except traffic lights\n",
    "5. Train the model - this, I cant do localy so its not in the notebook (this is either done on an EC2 machine or Google Colab)\n",
    "6. Review the results (confusion matrix, performance metrics and a couple of test examples)\n",
    "7. If we are not satisfied with the results, increase the amount of pictures with traffic lights by taking the pictures and annotations from the complete 100k dataset and/or reduce the amount of background pictures and repeat the process from step 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c4b68",
   "metadata": {},
   "source": [
    "#### Step 1 - Loading the json files and generating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41067b23-f757-482c-a75f-fc3108c9b4c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4c4af-8a78-42a3-a23d-b8e9f6e22c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(annotations_folder_path):\n",
    "    annotations = []\n",
    "    for annotation_name in tqdm(os.listdir(annotations_folder_path)):\n",
    "        annotation_path = os.path.join(annotations_folder_path, annotation_name)\n",
    "        annotation = json.load(open(annotation_path))\n",
    "        annotation[\"filename\"] = annotation_name.replace(\".json\", \"\")\n",
    "        annotations.append(annotation)\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5766df5-b573-48b4-8592-c6b14629d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_dict(input_dict, base_key=\"\", output_dict={}, index_value=None):\n",
    "    \n",
    "    for key in input_dict.keys():\n",
    "        \n",
    "        if base_key == \"\":\n",
    "            full_key = key     \n",
    "        else:\n",
    "            if index_value is None:\n",
    "                full_key = base_key + \"/\" + key\n",
    "            else:\n",
    "                full_key = base_key + \"/\" + key + \"/\" + index_value\n",
    "\n",
    "        if isinstance(input_dict[key], dict):\n",
    "            get_flattened_dict(input_dict[key], full_key, output_dict)\n",
    "            \n",
    "        elif isinstance(input_dict[key], list):\n",
    "            for index, item in enumerate(input_dict[key]):\n",
    "                full_list_key = full_key\n",
    "                get_flattened_dict(item, full_list_key, output_dict, str(index))\n",
    "                    \n",
    "        else:\n",
    "            output_dict[full_key] = input_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005aea6-8e89-4ef1-ad86-abaaa439fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_ORDER_DICT = {\n",
    "    \"description\": \"00-00000-00\",\n",
    "    \"tags\":[],\n",
    "    \"size\": {\n",
    "        \"width\": \"02-0000-00\",\n",
    "        \"height\": \"03-0000-00\"\n",
    "    },\n",
    "    \"objects\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46cd044-ab9c-4dd4-8e2a-18aeb7edc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_index(split_key, key_order_dict, level=0, id_value=None):\n",
    "    key = split_key[level]\n",
    "   \n",
    "        \n",
    "    if isinstance(key_order_dict[key], dict):\n",
    "        return get_column_index(split_key, key_order_dict[key], level+1, id_value)\n",
    "    \n",
    "    else:\n",
    "        column_index = key_order_dict[key]\n",
    "        if id_value is not None:\n",
    "            split_column_index = column_index.split(\"-\")\n",
    "            split_column_index[1] = split_column_index[1].replace(\"id\", id_value)[-5:]\n",
    "            column_index = \"-\".join(split_column_index)\n",
    "        return column_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc4bc4e-4b34-42ff-9a44-872a98ed0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_sorted_columns(annotation_df_columns):\n",
    "    sorted_annotation_df_cols = []\n",
    "    for annotation_df_col in annotation_df_columns:\n",
    "        split_col = annotation_df_col.split(\"/\")\n",
    "        col_index = get_column_index(split_col, KEY_ORDER_DICT, 0)\n",
    "        sorted_annotation_df_cols.append(str(col_index) + \"#\" + annotation_df_col)\n",
    "    sorted_annotation_df_cols.sort()\n",
    "    sorted_annotation_df_cols = [sorted_annotation_df_col.split(\"#\")[1] for sorted_annotation_df_col in sorted_annotation_df_cols]\n",
    "    return sorted_annotation_df_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad05be-5afa-410b-806b-4488c944975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_df(annotations):\n",
    "    annotation_dicts = []\n",
    "    for annotation in annotations:\n",
    "        annotation_dict = {}\n",
    "        get_flattened_dict(annotation, \"\", annotation_dict)\n",
    "        annotation_dicts.append(annotation_dict)\n",
    "    annotation_dicts_keys = set(list(itertools.chain.from_iterable([list(annotation_dict.keys()) for annotation_dict in annotation_dicts])))\n",
    "    annotation_dicts_keys = get_sorted_columns(list(annotation_dicts_keys))\n",
    "    annotation_df_dict = {key: [] for key in annotation_dicts_keys}\n",
    "    for annotation_dict in annotation_dicts:\n",
    "        for key in annotation_df_dict:\n",
    "            value = annotation_dict[key] if key in annotation_dict else np.nan\n",
    "            annotation_df_dict[key].append(value)\n",
    "    json_df = pd.DataFrame(annotation_df_dict)\n",
    "    return json_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2c68f-232c-4aa0-b129-19319ed3e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations_path = \"bdd100ksample/val/ann\"\n",
    "train_annotations = load_annotations(train_annotations_path)\n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame.from_dict(train_annotations, orient='columns')\n",
    "\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c859f",
   "metadata": {},
   "source": [
    "#### Step 2 - review tha dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ceaa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33efe7b",
   "metadata": {},
   "source": [
    "#### Step 3 - object counting and generating two more dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cd6f3-936b-44b5-9a5f-78784470087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "objetcs_id_dict = {\n",
    "    0: 'car',\n",
    "    1: 'bus',\n",
    "    2: 'drivable area',\n",
    "    3: 'lane',\n",
    "    4: 'traffic sign',\n",
    "    5: 'truck',\n",
    "    6: 'person',\n",
    "    7: 'traffic light',\n",
    "    8: 'rider',\n",
    "    9: 'bike',\n",
    "    10:'motor',\n",
    "    11:'train'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b704c0-49ee-4001-8b67-b40e036d1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totals = pd.DataFrame({\n",
    "    'car':[0],\n",
    "    'bus':[0],\n",
    "    'drivable area':[0],\n",
    "    'lane':[0],\n",
    "    'traffic sign':[0],\n",
    "    'truck':[0],\n",
    "    'person':[0],\n",
    "    'traffic light':[0],\n",
    "    'rider':[0],\n",
    "    'bike':[0],\n",
    "    'motor':[0],\n",
    "    'train':[0]\n",
    "})\n",
    "df_per_picture = pd.DataFrame({\n",
    "    'car':[0],\n",
    "    'bus':[0],\n",
    "    'drivable area':[0],\n",
    "    'lane':[0],\n",
    "    'traffic sign':[0],\n",
    "    'truck':[0],\n",
    "    'person':[0],\n",
    "    'traffic light':[0],\n",
    "    'rider':[0],\n",
    "    'bike':[0],\n",
    "    'motor':[0],\n",
    "    'train':[0]\n",
    "})\n",
    "\n",
    "for i in range(len(df2.index)): \n",
    "    picture_flags = [False, False, False, False, False, False, False, False, False, False, False, False]\n",
    "    for o in df2.loc[i,'objects']:\n",
    "        o_id = (o['classId']-6508800)\n",
    "        df_totals.loc[0,objetcs_id_dict[o_id]] = df_totals.loc[0,objetcs_id_dict[o_id]] + 1\n",
    "        if not picture_flags[o_id]:\n",
    "            df_per_picture.loc[0,objetcs_id_dict[o_id]] = df_per_picture.loc[0,objetcs_id_dict[o_id]] + 1\n",
    "            picture_flags[o_id] = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd21e5-87ab-412e-8354-3f4d39edcb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d629a-2107-485f-8956-fd20a9b39b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b93db",
   "metadata": {},
   "source": [
    "#### Step 4 - Generating the labels in YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c3cdfd-0d2c-43c3-b31e-5d580aa1481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df2.index)):\n",
    "    save_location = \"bdd100ksample/train/labels/\" + df2.loc[i,'filename'].rstrip('.jpg') + \".txt\"\n",
    "    file = open(save_location,'w')\n",
    "    for o in df2.loc[i,'objects']:\n",
    "        if o['classId'] - 6508800 != 7:\n",
    "            continue\n",
    "        str_line = \"\"\n",
    "        str_line += (\"0 \")\n",
    "        str_line += (str((o['points']['exterior'][1][0]+o['points']['exterior'][0][0])/(2*1280)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][1]+o['points']['exterior'][0][1])/(2*720)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][0]-o['points']['exterior'][0][0])/(1280)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][1]-o['points']['exterior'][0][1])/(720)) + \"\\n\")\n",
    "        file.write(str_line)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66730bbe",
   "metadata": {},
   "source": [
    "#### Step 5 - Train the model (code below shouldn't be here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8bd546-f57f-4f4c-935e-e5c71c6f671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8487964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.train(data='bdd100ksample/data.yaml', batch = 2, imgsz=1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f4f50",
   "metadata": {},
   "source": [
    "#### Step 6 - review the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355e45f-3726-4116-8d7f-fe6c61461483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307af4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "model = YOLO('mod2.pt')\n",
    "for img in tqdm(os.listdir( 'bdd100ksample/test/images')):\n",
    "    img_path = os.path.join('bdd100ksample/test/images', img)\n",
    "    imgs.append(img_path)\n",
    "    \n",
    "for img in imgs:\n",
    "    imgr = cv2.imread(img,1)\n",
    "    results = model(img)[0]\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "        cv2.rectangle(imgr, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "        cv2.putText(imgr, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "        cv2.imshow('',imgr)\n",
    "        if cv2.waitKey(0) == ord('q'):\n",
    "            break\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break      \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28831e10",
   "metadata": {},
   "source": [
    "Generisanje datafrejma - ceo dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc36e8",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde27da9-8e30-493a-8978-23227ad10b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations_path = \"bdd100k/train/ann\"\n",
    "train_annotations = load_annotations(train_annotations_path)\n",
    "\n",
    "df = pd.DataFrame.from_dict(train_annotations, orient='columns')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totals2 = pd.DataFrame({\n",
    "    'car':[0],\n",
    "    'bus':[0],\n",
    "    'drivable area':[0],\n",
    "    'lane':[0],\n",
    "    'traffic sign':[0],\n",
    "    'truck':[0],\n",
    "    'person':[0],\n",
    "    'traffic light':[0],\n",
    "    'rider':[0],\n",
    "    'bike':[0],\n",
    "    'motor':[0],\n",
    "    'train':[0]\n",
    "})\n",
    "df_per_picture2 = pd.DataFrame({\n",
    "    'car':[0],\n",
    "    'bus':[0],\n",
    "    'drivable area':[0],\n",
    "    'lane':[0],\n",
    "    'traffic sign':[0],\n",
    "    'truck':[0],\n",
    "    'person':[0],\n",
    "    'traffic light':[0],\n",
    "    'rider':[0],\n",
    "    'bike':[0],\n",
    "    'motor':[0],\n",
    "    'train':[0]\n",
    "})\n",
    "\n",
    "for i in range(len(df.index)): \n",
    "    picture_flags = [False, False, False, False, False, False, False, False, False, False, False, False]\n",
    "    for o in df.loc[i,'objects']:\n",
    "        o_id = (o['classId']-6508800)\n",
    "        df_totals2.loc[0,objetcs_id_dict[o_id]] = df_totals2.loc[0,objetcs_id_dict[o_id]] + 1\n",
    "        if not picture_flags[o_id]:\n",
    "            df_per_picture2.loc[0,objetcs_id_dict[o_id]] = df_per_picture2.loc[0,objetcs_id_dict[o_id]] + 1\n",
    "            picture_flags[o_id] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c379e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_totals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_picture2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b1812",
   "metadata": {},
   "source": [
    "Val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3406e228",
   "metadata": {},
   "source": [
    "Transformacija sample dataseta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca2b76",
   "metadata": {},
   "source": [
    "1. Brisanje svih slika i anotacija koje ne sadrze semafor u sebi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ca160-1063-4787-9a20-8c51d0bf7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_dict = {}\n",
    "\n",
    "for picture in tqdm(os.listdir('bdd100ksample/train/images')):\n",
    "       jpg_dict[picture] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a113d2-ed0e-4777-8cb2-ea9661edbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df2.index:\n",
    "    for obj in df2['objects'][ind]:\n",
    "        if (obj['classId']-6508800)==7:\n",
    "            jpg_dict[df2['filename'][ind]] = True\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24824091-948c-480d-b376-e36ab33f186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in jpg_dict:\n",
    "    if not jpg_dict[pair]:\n",
    "        os.remove('bdd100k/train/ann/'+pair+'.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdc1de",
   "metadata": {},
   "source": [
    "2. Kopiranje slika iz celog dataseta u sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpg_dict = {}\n",
    "\n",
    "for ind in df.index:\n",
    "    jpg_dict[df['filename'][ind]] = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61cfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for picture in tqdm(os.listdir('bdd100ksample/train/images')):\n",
    "       jpg_dict[picture] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ce3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "sem_picture_num = 900-435\n",
    "no_sem_picture_num = 27\n",
    "for ind in df.index:\n",
    "    pic_filename = df['filename'][ind]\n",
    "    \n",
    "    if jpg_dict[pic_filename]:\n",
    "        continue\n",
    "        \n",
    "    is_sem_pic = False\n",
    "    for obj in df['objects'][ind]:\n",
    "        if (obj['classId']-6508800)==7:\n",
    "            shutil.copyfile('bdd100k/train/ann/'+pic_filename+'.json', 'bdd100ksample/train/ann/'+pic_filename+'.json')\n",
    "            shutil.copyfile('bdd100k/train/images/'+pic_filename, 'bdd100ksample/train/images/'+pic_filename)\n",
    "            sem_picture_num-=1\n",
    "            is_sem_pic = True\n",
    "            break\n",
    "    if not is_sem_pic and no_sem_picture_num > 0:\n",
    "        shutil.copyfile('bdd100k/train/ann/'+pic_filename+'.json', 'bdd100ksample/train/ann/'+pic_filename+'.json')\n",
    "        shutil.copyfile('bdd100k/train/images/'+pic_filename, 'bdd100ksample/train/images/'+pic_filename)\n",
    "        no_sem_picture_num-=1\n",
    "    if no_sem_picture_num==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c6f8b7",
   "metadata": {},
   "source": [
    "Prikaz rezultata sa poboljsanim sample datasetom ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd85fb",
   "metadata": {},
   "source": [
    "Transformacija celog dataseta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9c7c8",
   "metadata": {},
   "source": [
    "1. Smanjivanje broja slika bez semafora na 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_no_sem = 1000\n",
    "for ind in df.index:\n",
    "    to_delete = True\n",
    "    for obj in df['objects'][ind]:\n",
    "        if (obj['classId']-6508800)==7:\n",
    "            to_delete = False\n",
    "            break\n",
    "    if total_no_sem>0:\n",
    "        total_no_sem -=1\n",
    "        to_delete = False\n",
    "    if to_delete:\n",
    "        os.remove('bdd100k/train/ann/'+pair+'.json')\n",
    "        os.remove('bdd100k/train/images/'+pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb7045",
   "metadata": {},
   "source": [
    "ponovno ucitavanje dataseta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations_path = \"bdd100k/train/ann\"\n",
    "train_annotations = load_annotations(train_annotations_path)\n",
    "\n",
    "df = pd.DataFrame.from_dict(train_annotations, orient='columns')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b5c98a",
   "metadata": {},
   "source": [
    "2. Transformacija u yolo format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a866d180-701f-46e3-ae42-e7f171145b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#srediti jos\n",
    "\n",
    "for i in range(len(df.index)):\n",
    "    save_location = \"bdd100k/train/labels/\" + df.loc[i,'filename'].rstrip('.jpg') + \".txt\"\n",
    "    file = open(save_location,'w')\n",
    "    for o in df.loc[i,'objects']:\n",
    "        if o['classId'] - 6508800 != 7:\n",
    "            continue\n",
    "        str_line = \"\"\n",
    "        str_line += (\"0 \")\n",
    "        str_line += (str((o['points']['exterior'][1][0]+o['points']['exterior'][0][0])/(2*1280)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][1]+o['points']['exterior'][0][1])/(2*720)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][0]-o['points']['exterior'][0][0])/(1280)) + \" \")\n",
    "        str_line += (str((o['points']['exterior'][1][1]-o['points']['exterior'][0][1])/(720)) + \"\\n\")\n",
    "        file.write(str_line)\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71bd8a",
   "metadata": {},
   "source": [
    "Prikaz rezultata nad celim skupom..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6d538-be9c-4f4b-a650-296c8b16f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.index)): \n",
    "    img = cv2.imread(\"bdd100k/train/images/\"+df.loc[i,'filename'],1)\n",
    "   # print(i)\n",
    "    for o in df.loc[i,'objects']:\n",
    "        o_id = (o['classId']-6508800)\n",
    "        if o_id != 7:\n",
    "            continue\n",
    "        cv2.rectangle(img,(o['points']['exterior'][0][0],o['points']['exterior'][0][1]),(o['points']['exterior'][1][0],o['points']['exterior'][1][1]),(0,0,255),2)\n",
    "        cv2.imshow(df.loc[i,'filename'],img)\n",
    "        if cv2.waitKey(0) == ord('q'):\n",
    "            break\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break      \n",
    "    cv2.destroyAllWindows()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b6683",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "VIDEOS_DIR = os.path.join('.', 'videos')\n",
    "\n",
    "video_path = 'vid5.mp4'\n",
    "video_path_out = '{}_out.mp4'.format(video_path)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "ret, frame = cap.read()\n",
    "H, W, _ = frame.shape\n",
    "out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))\n",
    "\n",
    "\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('mod.pt')  # load a custom model\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "while ret:\n",
    "\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, score, class_id = result\n",
    "\n",
    "        if score > threshold:\n",
    "            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)\n",
    "            cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "    out.write(frame)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda346ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
